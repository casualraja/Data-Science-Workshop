{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 6.04 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbC/8KAgpg7jx+BEo4PFYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casualraja/Data-Science-Workshop/blob/Exercises/Exercise_6_04_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32cbfKCGQnGh",
        "colab_type": "text"
      },
      "source": [
        "**Computing the Mean Absolute Error of a Second Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuZ5JUqIQ4pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "# pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "# preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDROy-tRywx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# column headers\n",
        "_headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc', 'MLOGP', 'response']\n",
        "# read in data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter06/Dataset/qsar_fish_toxicity.csv', names=_headers, sep=';')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3brUGAw3SLe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's split our data\n",
        "features = df.drop('response', axis=1).values\n",
        "labels = df[['response']].values\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.2, random_state=0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7xKKDx1SYts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a pipeline and engineer quadratic features\n",
        "steps = [ \n",
        "         ('scaler', MinMaxScaler()),\n",
        "         ('poly', PolynomialFeatures(2)),\n",
        "         ('model', LinearRegression())\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ar-R3gMTiuQ",
        "colab_type": "text"
      },
      "source": [
        "In this step, you begin by creating a Python list called steps. The list contains three tuples, each one representing a transformation of a model. The first tuple represents a scaling operation. The first item in the tuple is the name of the step, which you call scaler. This uses MinMaxScaler to transform the data. The second, called poly, creates additional features by crossing the columns of data up to the degree that you specify. In this case, you specify 2, so it crosses these columns up to a power of 2. Next comes your LinearRegression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZM6FH08TOQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create pipeline:\n",
        "# create a simple Linear Regression model with a pipeline\n",
        "model = Pipeline(steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3kegFNsUAW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "41ca28da-094d-4807-f236-27698760a7eb"
      },
      "source": [
        "# train the model\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
              "                ('poly',\n",
              "                 PolynomialFeatures(degree=2, include_bias=True,\n",
              "                                    interaction_only=False, order='C')),\n",
              "                ('model',\n",
              "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
              "                                  normalize=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVSFZbUvUeYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's use our model to predict on our validation dataset\n",
        "y_pred = model.predict(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQR5YdQ8U0e9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98839c8f-a14d-446a-8e64-487a3b2fcd9d"
      },
      "source": [
        "# Let's compute our MEAN ABSOLUTE ERROR\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "print('MAE: {}' .format(mae))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 0.6605526100836078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dv6cnVMVfq_",
        "colab_type": "text"
      },
      "source": [
        "The loss that was computed at this step is called validation loss because you make use of the validation dataset.  This is different from training loss that is computed using the training dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "399V2YxIVae2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efeb2325-eee1-4f32-971a-3bc0bd09773e"
      },
      "source": [
        "# Let's get the R2 score\n",
        "r2 = model.score(X_val, y_val)\n",
        "print('R^2 score: {}'.format(r2))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2 score: 0.6284921344153389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1EUNskCXWtv",
        "colab_type": "text"
      },
      "source": [
        "In this exercise, you engineered new features that give you a model with a hypothesis of a higher polynomial degree. This model should perform better than simpler models up to a certain point. After engineering and training the new model, you computed the R2 score and MAE, which you can use to compare this model with the model you trained previously. We can conclude that this model is better as it has a higher R2 score and a lower MAE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DOsCgpfW4NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}